# Data Structure 1：Bloom Filter
## Part1：Bloom Filter的介绍

布隆过滤器（英语：Bloom Filter）是 1970 年由布隆提出的。``它实际上是一个很长的二进制向量和一系列随机映射函数``。布隆过滤器是一种节省空间的``概率数据结构``。可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。

> 我在学习布隆过滤器中认为它的特性与其他以往学过的数据结构差别最大是``布隆过滤器判断存在的不一定存在，但是判断不存在的一定不存在。``即 **False is always false.True is maybe true**

## Part2: Bloom Filter 的引入--BitMap（位图）
- **位图**是一种用位运算操纵 bit 位实现 0/1 数据的``高效存储的数据结构``。它相比于字节、字等单位尺度更低，更节省空间。但只能标记数据的存在和不存在，不能计数。``用于对大量整型数据做去重和查询``。

- **示例1**：我们有 1 千万个整数，整数的范围在 1 到 1 亿之间。如何快速查找某个整数是否在这 1 千万个整数中呢？
    - 可以使用**位图**申请 1 亿个 bit 型数组，并初始化全部为 0，将 1 千万个整数作为数组下标，将对应的数组值设置为 1。
    - 那么我们要查找一个数 k 是否在 1 千万个整数中时只要将对应的 array[k] 取出来看是否为 1 即可。
    - 原本 1 千万个整数需要 10000000*4 字节空间，现在只需要 1 亿个 bit 位。``既减少空间又提高查找效率``。

- **使用哈希函数进一步提升**：如上示例我们需要数组长度必须大于最大整数的上限。
    - 如果我们希望将数组长度压缩到一个足够小的值之内，我们就需要``使用哈希函数将大于数组长度的，转换为一个小于数组长度的数值作为下标``。
    - 除此以外，使用哈希函数也带来了另一个优点，那就是我们不需要把存储类型限制为正整数了，它也可以是字符串。这样一来，压缩数组长度，并使用哈希函数，就是一个更加通用的解决方案。

- **示例2**：用户注册时候的名字如果已经存在就不可以再注册
    - 将所有用户的名字经过哈希函数存储在一个 bit 数组中，那么重新注册的名字只需要查询哈希后对应的数组下标是否为 1，若为 1 则提示用户更改用户名。

## Part3：Bloom Filter 的基本原理
### 1.面临的问题
如上使用“位图 + 一个哈希函数”这种哈希表法，可以大大减少空间和提升效率，但和其他哈希表一样会面临相同的问题：数组越小，发生哈希冲突的可能性越大。于是在大数据的今天，我们提出新的问题：``如何在压缩空间的前提下缓解哈希冲突``？

### 2.Bloom Filter 的核心思想
- 在哈希表这种数据结构中已经提出一种解决哈希冲突的方案，即开放地址法的“双散列”，基本原理是使用多个哈希函数，当第一个哈希函数冲突的情况下使用第二种哈希函数重新选择存储位置。
- 基于这种思想，**布隆过滤器**使用了多个哈希函数来降低哈希冲突。其主要特点是，``对每一个存储对象使用了多个哈希函数，即得到多个哈希值，也就会在 array 数组中 k 个位置设置为 1``。布隆过滤器和位图最大的区别就在于，``数组不再使用一位来表示一个对象，而是使用 k 位来表示一个对象``。这样两个对象的 k 位都相同的概率就会大大降低，从而能够解决哈希冲突的问题了。

### 3.Bloom Filter 的基本操作
你可以使用[图形化网站工具](https://www.jasondavies.com/bloomfilter/)进行尝试
- **插入**：上述提到在使用布隆过滤器的数据结构来存储的数据会对每一个存储对象经过 k 次哈希函数，得到 k 个哈希值，也就会在 array 数组中 k 个位置设置为 1。
    - 如下图示例：对于此图，m = 18 and k = 3。集合{x，y，z}存储到数组中。彩色箭头显示每个设置元素映射到的位数组中的位置，分别对应 x、y、z 元素经过三次哈希函数得到的三个哈希值。

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/Bloom02.png)

- **查询**：
    - 如上图我们对所要查询的对象 w 同样进行三次哈希函数，得到三个哈希值分别对应三个数组下标。
        - 如果得到的哈希值所对应的数组下标位置的值``全部为 1``，则认为该查询对象``大概率已经存在``。
        - 如果得到的哈希值中有一个为 0，则认为该查询对象``一定不存在``。
        > 对此可以再深入理解开头即说的“**False is always false.True is maybe true**”
    - 原因是待查询的对象经过哈希运算后，有可能使其得到的三个下标值对应的位置已经被其他已存储的元素设置为 1。例如，上图中的 w，加入最后一个哈希值再大一个数，则因为已经存储的 x、y 所设置的 1 的下标和 w 经过哈希运算后的下标相同，导致了**误判**发生。
        - 这也说明了哈希冲突永远存在，但布隆过滤器已经再试图减少冲突的发生。
    - **误判**的发生我们要理性看待，再众多数据的查询中，少有的误判可以容忍，且换来更高效的效率和低存储空间。

- **~~不支持~~ 删除**
    - 布隆过滤器是不支持删除元素的。
        - 直接上，我肯对待删除的元素进行哈希运算后，将对应哈希值的下标由 1 设置为 0即可。但如此一来，如上图示例，我们删除 x，并将相应下标设置为 0 后，再查询 z，会发现由哈希值对应下标为 0，进而判断 z 不存在；这无疑是错误的。

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/Bloom%E3%80%8203.png)
    - **Counting Bloom Filter**<br>
    为了解决删除这种需求，而提出 CBF 法。计数布隆过滤器使用的功能与布隆过滤器相同，但主要区别在于在计数布隆过滤器中，我们在``每个插槽中添加了计数器``，而不是（0或1）。这意味着我们可以从数据结构中删除元素。下例很容易理解 CBF 的设计。
        1. 要初始化计数布隆过滤器，我们应该创建一个多 bit 数组，每个插槽中都将容纳一个计数器的值。开始时，所有时隙将等于零，因为在数据结构中未添加任何元素。

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/CBF01.png)
        2. 我们插入 “Battlefield” ，经过三个哈希函数，并将数组中相应下标加 1。

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/CBF02.png)
        3. 我们插入 “GAT” ，在这里，我们可以注意到插槽号3增加了1，因为两个哈希函数输出在此处相交。    

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/CBF03.png)
        4. **删除 Battlefieled**，从数据结构中删除元素具有与添加类似的方法。因此，要删除元素，我们首先需要使用哈希函数查找元素的键。之后，我们将使用找到的键进入插槽，然后将这些插槽值减一。

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/CBF04.png)
        5. 当再次查找 “Battlefield” 和 “GAT” ，我们可以发现可以得到我们想要的查询结果。

## Part4：误报率的影响因素
当设计布隆过滤器时候，我们应使得误报率越小越好，如下图：k 为哈希函数个数，m 为布隆过滤器长度，n 为插入的元素个数，p 为误报率

![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/CBF06.png)
<br>由图可直接观察出
- 当布隆过滤器长度和插入元素数相同时，无论多少哈希函数都将使得误报率接近与 100%。这是因为我们已经将数组填充满了，那么再将任何值进行哈希所查到的都是为 1 的哈希值，也就 100% 误报了。
- 当过滤器的长度越来越长时会降低误报率，``但误报率永远不会为 0``。
- 随着哈希函数的数量增加也会降低误报率。

但我们也不得不考虑当过滤器长度增加时导致``空间浪费``；以及当哈希函数增加时，导致每次对象计算次数增加导致的``时间效率降低``。<br>
我们可以根据[数学推导](https://en.wikipedia.org/wiki/Bloom_filter#Probability_of_false_positives)得到最佳的哈希函数个数 k 和过滤器长度 m    <div align=center>![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/CBFmk.png)</div>


## Part5：Bloom Filter 的其他
### 1.Bloom Filter 的特点
- 布隆过滤器没有错误的负输出，这意味着当特定值不存在时，它永远不会说该特定值存在。
- 它具有假阳性概率，这意味着它可以说某物存在而没有。当散列函数的输出针对不同元素重叠时，就会发生该问题。
- 布隆过滤器使用位的大小（0或1）来存储标记一个插槽。
- 在初始化中，布隆过滤器的特定大小（m）为零，该大小会影响获得假阳性的可能性。

### 2.优点
- 存储空间和插入/查询时间都是常数，远远超过一般的算法；
- Hash函数相互之间没有关系，方便由硬件并行实现；
- 不需要存储元素本身，在某些对保密要求非常严格的场合有优势；
- 耗费的空间减少到散列表的1/8到1/4。

### 3.缺点
- 有一定的误识别率；
- 删除困难。

### 4.Bloom Filter 的应用
- Google 的分布式数据库 Bigtable 使用了布隆过滤器来查找不存在的行或列，以减少磁盘查找的I0次数；
- Squid 网页代理缓存服务器在cache digests中使用了也布隆过滤器；
- Venti 文档存储系统也采用布隆过滤器来检测先前存储的数据；
- SPIN模型检测器也使用布隆过滤器在大规模验证问题时跟踪可达状态空间；
- Google Chrome 浏览器使用了布隆过滤器加速安全浏览服务；
- 很多Key-Value系统也使用布隆过滤器来加快查询过程，如Hbase，Accumulo，Leveldb。一般而言，Value保存在磁盘中，访问磁盘需要花费大量时间，然而使用布隆过滤器可以快速判断某个Key对应的Value是否存在，因此可以避免很多不必要的磁盘I0操作。

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/Bloom01.png)

## References
- [Hash和Bloom Filter](http://www.sigma.me/2011/09/13/hash-and-bloom-filter.html)
- [Bitmap算法](https://mp.weixin.qq.com/s/xxauNrJY9HlVNvLrL5j2hg)
- [What are Counting Bloom Filters? — Python Implementation](https://medium.com/analytics-vidhya/cbfs-44c66b1b4a78)
- [Counting Bloom Filter 的原理和实现](https://cloud.tencent.com/developer/article/1136056)

# Data Structure 2：Cuckoo Filter
上述可知标准的 Bloom Filter 有一个局限性，即不重建整个过滤器，就无法移除现有的项目。有其他方法可以扩展标准 Bloom Filter 实现删除功能，但空间和性能上开销很大。

## Part1：Cuckoo Filter 的介绍
布谷鸟过滤器于2014年首次描述。布谷鸟过滤器是一种节省空间的``概率数据结构``，像布隆过滤器一样，它用于测试元素是否是集合的成员。``可能会出现假阳性匹配，但否定假匹配``。布谷鸟过滤器还可以删除现有项目，布隆过滤器不支持。此外，对于存储许多物品并以适度较低的误报率为目标的应用程序而言，布谷鸟过滤器可以比空间优化的布隆过滤器实现更低的空间开销。

布谷鸟过滤器的四个优点：
1. 支持动态添加和删除项目。
2. 它比传统的Bloom过滤器提供了更高的查找性能，甚至在接近完全时（例如，95%的空间利用率）
3. 更容易实现
4. 如果误报率小于 3%，则在很多实际应用中使用的空间比布隆过滤器小。

## Part2：Cuckoo Filter 的基本原理
### 1.基本描述
- 首先描述一种动物-布谷鸟，布谷鸟喜欢滥交（自由），从来不自己筑巢。它将自己的蛋产在别人的巢里，让别人来帮忙孵化。待小布谷鸟破壳而出之后，因为布谷鸟的体型相对较大，它又将养母的其它孩子（还是蛋）从巢里挤走 —— 从高空摔下夭折了，即「鸠占鹊巢」。
- **布谷鸟哈希算法**：待插入的元素如同布谷鸟一样喜欢“占用”且“挤走”其他元素。``一个基本的布谷哈希表由一个 Bucket 数组和两个哈希函数组成``。其中每一个 Bucket 的位置是由这两个哈希函数决定。
    - 如下图是一个 8 个空间的 Bucket 数组，x 经过两个哈希函数 h1 和 h2 之后可以将 x放在 Bucket[2] 或 Bucket[6]，如果两个位置有一个为空则存入空位置，如果两个位置都为空，则任意存一个位置。
    - 若两个位置都不为空，则我们任意选择一个位置插入，下图示例插入 Bucket[6]，则原位置的 a 如同鸟蛋一样被“挤走”。
    - 之后 a 本经过两次哈希后有两个位置可以插入，从当前位置“被挤走”后会选择另一个位置插入，下图示例中插入 Bucket[4]，且“挤走” c。
    - c 再如同 a 一样寻找下一个“容身之所”进行插入。
    - 最终效果如图右所示。

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/CuckooF01.png)
    - 如上述所表现了布谷鸟过滤器的核心思想“**占自己的巢，让别人滚蛋去吧**！”可当数组太拥挤会出现踢来踢去都停不下来，影响插入效率。这时候需要``设置一个阈值``，如果“占巢”行为达到阈值就认定数组将满，``采取扩容处理，重新放置所有元素``。
- 对于**布谷鸟过滤器**还需要了解过滤器所存储的并非是原本插入的数据，而是指纹。

### 2.插入元素
- 上述已经将一个标准的布谷鸟插入过程进行了描述。那有个问题是：如果我们像过去布隆过滤器的哈希函数一样，根据元素来查找哈希值。那当元素“被挤走”时因为所存储的是指纹而非原数据，便不能找的另一个替代位置？
- 为解决问题，布谷鸟过滤器的作者巧妙运用了一个``异或``运算来解决。
    - 异或有一个对偶性质是：b⊕a⊕a=b，则对于输入的 x
    ```java
    h1 = hash(x)
    h2 = h1 ⊕ hash(fp)
    ```
    - 则根据性质 h1 = h2 ⊕ hash(fp)，根据此对偶性质可以很方便求得一个指纹的两个位置。
- 插入元素的伪码如下图

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/CuckooF02.png)

### 3.查找元素
- 给定一个 x，查找是一个比较简单的过程：
    1. 首先根据下述公式计算 x 的位置
    ```java
    h1 = hash(x)
    h2 = h1 ⊕ hash(fp)
    ```
    2. 然后读取两个位置的指纹,任意一个指纹与 x 指纹相同则返回 true；否则返回 false。
- 查找的伪码

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/CuckooF03.png)

### 4.删除元素
- 删除与查找算法很相似，只要我们能查得到，就可以直接删除
- 删除伪码

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/CuckooF05.png)

## Part3：优化
### 1.问题描述
- 综上所述，标准布谷鸟很容易出现多元素哈希位置是相同的位置（类似于重复输入一个元素），那么假如已经有两个元素哈希和指纹相同已经占据两个位置，再出现一个哈希和指纹相同的元素插入就会出现死循环的出现，从而触发了扩容操作，但此问题单单扩容不能解决
- 上面的标准布谷鸟的空间利用率只有 50%。
### 2.解决方法
- 方案一：增加 hash 函数，让每个元素不止有两个巢，而是三个巢、四个巢。这样可以大大降低碰撞的概率，将空间利用率提高到 95%左右。

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/CuckF06.png)
- 方案二：数组的每个位置上挂上多个座位，这样即使两个元素被 hash 在了同一个位置，也不必立即「鸠占鹊巢」，因为这里有多个座位，你可以随意坐一个。除非这多个座位都被占了，才需要进行挤兑。很明显这也会显著降低挤兑次数。这种方案的空间利用率只有 85%左右，但是查询效率会很高，同一个位置上的多个座位在内存空间上是连续的，可以有效利用 CPU 高速缓存。
- 方案三：更加高效的方案是将上面的两个改良方案融合起来，比如使用 4 个 hash 函数，每个位置上放 2 个座位。这样既可以得到时间效率，又可以得到空间效率。这样的组合甚至可以将空间利用率提到高 99%，这是非常了不起的空间效率。

## References
1. [Cuckoo Filter: Practically Better Than Bloom](https://www.cs.cmu.edu/~dga/papers/cuckoo-conext2014.pdf)（论文）
2. [布隆过滤器过时了，未来属于布谷鸟过滤器？](https://cloud.tencent.com/developer/article/1447177)

# Data Structure 3：Consistent Hash
## Part1：Consistent Hash 介绍
- 一致哈希（Consistent Hash）是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变``平均只需要对 K/n 个关键字重新映射``，其中 K 是关键字的数量，n 是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。
- 为了``解决分布式 web 中的热点问题``，David Karger 于 1997 年提出一致性哈希(Consistent Hashing)，论文请见 [Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web(较难理解)](https://www.akamai.com/es/es/multimedia/documents/technical-publication/consistent-hashing-and-random-trees-distributed-caching-protocols-for-relieving-hot-spots-on-the-world-wide-web-technical-publication.pdf)
- 现在一致性 hash 算法在``分布式系统``中也得到了广泛应用

## Part2：一般哈希算法遇到的问题
- **场景描述**：我们有三台缓存服务器，用于缓存图片，我们为这三台缓存服务器编号为0号、1号、2号，现在，有3万张图片需要缓存，我们希望这些图片被均匀的缓存到这3台服务器上，以便它们能够分摊缓存的压力。也就是说，我们希望每台服务器能够缓存1万张左右的图片，那么，我们应该怎样做呢？
- **一般哈希算法**：我们选择图片的唯一标识，这里我们认为是名称。
    - 那么当我们对同一个图片名称做相同的哈希计算时，得出的结果应该是不变的。
    - 如果我们有3台服务器，使用哈希后的结果对3求余，那么余数一定是0、1或者2，没错，正好与我们之前的服务器编号相同，如果求余的结果为0，我们就把当前图片名称对应的图片缓存在0号服务器上，如果余数为1，就把当前图片名对应的图片缓存在1号服务器上，如果余数为2。
    - 同理，那么，当我们访问任意一个图片的时候，只要再次对图片名称进行上述运算，即可得出对应的图片应该存放在哪一台缓存服务器上，我们只要在这一台服务器上查找图片即可。
    - 如果图片在对应的服务器上不存在，则证明对应的图片没有被缓存，也不用再去遍历其他缓存服务器了。
    - 通过这样的方法，即可将3万张图片随机的分布到3台缓存服务器上了，而且下次访问某张图片时，直接能够判断出该图片应该存在于哪台缓存服务器上，这样就能满足我们的需求了。<center>![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/consistentHash01.png)</center>

- **遇到的问题**：当我们的需求发生改变时，例如图片增加需要添加新服务器或者减少服务器时两种情况。
    - 假设，我们增加了一台缓存服务器，那么缓存服务器的数量就由3台变成了4台，此时，如果仍然使用上述方法对同一张图片进行缓存，那么这张图片所在的服务器编号必定与原来3台服务器时所在的服务器编号不同，因为除数由3变为了4，被除数不变的情况下，余数肯定不同，这种情况带来的结果就是当服务器数量变动时，所有缓存的位置都要发生改变
    - 当服务器数量发生改变时，所有缓存在一定时间内是失效的，当应用无法从缓存中获取数据时，则会向后端服务器请求数据。由于大量缓存在同一时间失效，造成了``缓存的雪崩``，此时前端缓存已经无法起到承担部分压力的作用，后端服务器将会承受巨大的压力，整个系统很有可能被压垮。

## Part3：Consistent Hash 的基本原理
- 一致性哈希算法原理
    1. 将每个节点(node)映射到数值空间 [0, 2^32 - 1]，映射的规则可为 IP、hostname 等。
    2. 将每个 object 映射到数值空间 [0, 2^32 - 1]。
    3. 对于某个 object，对于所有满足 hash(node) <= hash(object) 的节点，选择 hash(node) 最大的节点存放 object。如果没有满足上述条件的节点，选择 hash(node) 最小的节点存放该 object，如下图

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/ConsistentHash02.png)
- **减少**：当有某个节点宕机时，仅有该节点的对象需要重新哈希到新节点上

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/hashringdelete.png)
- **添加**：当新增一个节点时，仅有一个节点的部分 object 需要重哈希

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/hashringadd.png)

- **哈希环的偏斜**：当集群中的节点数量较少时，可能会出现节点在哈希空间中分布不平衡的问题。即平衡性低，如下图所示：

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/hashringubalance.png)
- **虚拟节点的引入**：解决哈希环偏斜问题的方法就是，让集群中的节点尽可能的多，从而让各个节点均匀的分布在哈希空间中。在现实情境下，机器的数量一般都是固定的，所以我们只能将现有的物理节通过虚拟的方法复制多个出来，这些由实际节点虚拟复制而来的节点被称为虚拟节点。加入虚拟节点后的情况如下图所示：

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/hashringvn.png)

## Part4：判定哈希算法好坏的四个定义
1. 平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。
2. 单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。
3. 分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是``尽量降低分散性``。
4. 负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够``尽量降低缓冲的负荷``。

## References
1. [白话解析：一致性哈希算法 consistent hashing](https://www.zsythink.net/archives/1182)
2. [理解 Consistent Hashing](http://wsfdl.com/algorithm/2017/01/28/%E7%90%86%E8%A7%A3%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C.html)
3. https://blog.csdn.net/cywosp/article/details/23397179

# Data Structure 4：Chord 环
## Part1：Chord 介绍
- 在``对等网络``中面临的一个最基本问题是``高效地定位存储特定数据项的节点``。
- Chord 是一个解决这个问题的分布式``查找协议``。
- Chord 只支持一个操作：给定一个键，它将键映射到一个节点上。通过将一个键与每个数据项关联，并将键/数据项对存储在键映射到的节点上，可以轻松地在 Chord 上实现``数据定位``。
- Chord ``可以有效地适应节点加入和离开系统``。因为 Chord ``使用一致性哈希的变体为 Chord 节点分配键``。一致性哈希可以平衡负载，使每个节点接收的密钥数量大致相同，当节点加入和离开系统时涉及到相对较少的关键点移动。

## Part2：P2P 中常见的定位数据方法
1. Napster：``使用一个中心服务器接收所有的查询``，服务器告知去哪下载其所需要的数据。存在的问题是中心服务器单点失效导致整个网络瘫痪。

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/chord01.png)
2. Gnutella：使用消息洪泛（message flooding）来定位数据。``一个消息被发到系统内每一个节点，直到找到其需要的数据为止``。当然，使用生存时间（TTL）来限制网络内转发消息的数量。存在的问题是消息数与节点数成线性关系，导致网络负载较重。

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/chord02.png)
3. SN 型：现在大多数采用所谓超级节点（Super Node），``SN 保存网络中节点的索引信息``，这一点和中心服务器类型一样，但是网内有多个 SN，其索引信息会在这些SN中进行传播，所以整个系统的崩溃几率就会小很多。尽管如此，网络还是有崩溃的可能。

## Part3：Chord 原理
上述介绍中提到 Chord 协议只支持查找，即根据一个 key 来映射到某个节点上。但实际应用中，节点中除了存储 key 还需要存储其他信息 Value。
- 分布式哈希表系统（Distributed Hash Table，DHT）核心思想
    - 首先，``每条文件索引被表示成一个(K, V)对``，K 称为关键字，可以是文件名（或文件的其他描述信息）的哈希值，V 是实际存储文件的节点的IP地址（或节点的其他描述信息）。
    - 所有的文件索引条目(即所有的（K, V）对)组成一张大的文件索引哈希表，``只要输入目标文件的 K 值，就可以从这张表中查出所有存储该文件的节点地址``。
    - 然后，再将上面的大文件哈希表分割成很多局部小块，按照特定的规则把这些小块的局部哈希表分布到系统中的所有参与节点上，使得``每个节点负责维护其中的一块``。
    - 这样，节点查询文件时，``只要把查询报文路由到相应的节点即可``（该节点维护的哈希表分块中含有要查找的(K,V)对）。
- Chord 的组成
    1. 节点 ID：NID（node identifier），``表示一个物理机器``，m 位的一个数字（m 要足够大以保证不同节点的 NID 相同的几率小的可以忽略不计），由节点机器的 IP 地址通过哈希操作得到。
    2. 资源 ID；KID（key identifiers），原为键 ID，其实际``表示一个资源``（因为 Key 与一个资源 value 哈希绑定），故在本文中统称资源 ID（这样比较直观），m 位的一个数字（m 要足够大以保证不同资源的 KID 相同的几率小的可以忽略不计），由 Key 通过哈希操作得到。
    3. 哈希函数：Chord 选择 ``SHA-1`` 作为哈希函数，SHA-1会产生一个 2^160 的空间，每项为一个 16 字节（160 bit）的大整数。则 ``m=160``
    4. Chord 环：Chord Ring，NID 和 KID 被分配到一个大小为 2^m 的环上，用于资源分配（给某一个节点）和节点分布，以及资源定位（注：在这个环上的 ID 为 0--2^m-1 ）。首先我们说资源分配，资源被分配到 NID >= KID 的节点上，这个节点成为 k 的后继节点，是环上从 k 起``顺时针方向``的第一个节点，记为 successor(k)。而``节点分布则顺时针将节点N由大到小放在这个环上``。
    - 下图示例是一个 m=6 的环，其中有 10 个节点，5 个资源，K10 的后继节点为 N14，也就是说 K10 被分配给了 N14

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/chord03.png)

## Part4：Chord 的操作
- **查找资源**：某一节点 n 要求寻找 KID=id 的资源
    - 简单方法
        1. 节点 n 首先询问是否在下一节点，即查看资源 K 的 KID 是否在 当前节点的NID 与 下一节点的 NID 之间
        2. 若 idє(当前节点 NID，下一节点 NID]，则可在下一节点中找到目标资源
        3. 若不在，则由下一个节点发起同样的查询，询问下下一个节点是否有目标资源
        4. 迭代循环至找到目标资源
    - 可伸缩的方法：显然简单方法容易理解，但效率很低。
        - 本方法``在每一个节点上维护一个小于 m 项的路由表，用来方便定位资源``。如下图举例，让节点 N8 寻找 K54 的资源

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/chord04.png)
        1. 首先，在 N8上 查找后继节点为 N14 ，发现 K54 并不符合 54є (8; 14] 的要求，那么直接在 N8 的路由表上查找符合这个要求的表项（由远及近查找），此时 N8的路由表如上图可知。
        2. 我们发现路由表中最远的一项 N8+32--N42 满足 42є (8; 54]，则说明 N42 这个点离持有 K54 这个资源的节点最近（因为 N42 在该路由表中离N8这个节点最远），那么此时跳到 N42 这个节点上继续查找。N42 的后继节点为 N48，不符合 54є (42; 48] 的要求，说明 N48 不持有资源 K54，此时，开始在 N42 的路由表上查找：

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/chord05.png)
        3. 我们由远及近开始查找，发现 N42+8--N51 满足 51є (42; 54]，则说明 N5 1这个点离持有 K54 这个资源的节点最近，那么此时跳到 N51 这个节点上继续查找。N51 节点的后继节点为 N56，符合 54є (51; 56]，此时定位完成，N56 持有资源节点 K54。

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/chord06.png)
        - 伪码如下图

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/chord07.png)
- **添加节点**
    - Chord 实现增删节点前提
        - Chord 要维护好每一个节点的后续节点
        - 后继节点存储好该节点相应的资源
        - 维护好每一个节点的路由表
        - 我们也要知道``每一个节点都维护一个前置指针，可以用来逆时针绕标识符圆圈走``。Chord通过在每个节点的后台周期性的进行询问后继节点的前驱节点是不是自己来更新后继节点以及路由表中的项。
    - 示例如下
        1. 原本结构如图

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/chord08.png)
        2. 现在 N26 节点要加入系统，首先它指向其后继 N32，然后通知 N32，N32 接到通知后将 N26 标记为它的前序节点（predecessor）。如下图：

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/chord9.png)
        3. 然后N26修改路由表，如下图

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/chord10.png)
        4. 下一次 Chord ``周期性循环检测前驱节点时``，到 N21 运行时询问其后继节点 N32 的前序节点是不是还是自己，此时发现N32 的前序节点已经是 N26：于是N21就将后继节点修改为N26，并通知N26自己已经将其设置为后继节点，N26接到通知后将N21设置为自己的前序节点。

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/chord11.png)




## References
1. [Chord: A Scalable Peer-to-peer Lookup Service for Internet
Applications](https://pdos.csail.mit.edu/papers/chord:sigcomm01/chord_sigcomm.pdf)（论文）
2. [P2P中的Chord算法](https://www.cnblogs.com/gnuhpc/archive/2012/01/13/2321476.html)