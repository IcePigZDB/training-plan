 # Data Structure 1:SkipList 学习

 ## Part1:SkipList 介绍
 &ensp;&ensp;&ensp;&ensp;在计算机科学中，``SkipList 是一种数据结构``。它使得包含 n 个元素的有序序列的查找和插入操作的平均时间复杂度都是 O(logn)，优于数组的 O(n) 复杂度。<br>
 &ensp;&ensp;&ensp;&ensp;快速的查询效果是``通过维护一个多层次的链表实现的``，且与前一层（下面一层）链表元素的数量相比，每一层链表中的元素的数量更少。一开始时，算法在最稀疏的层次进行搜索，直至需要查找的元素在该层两个相邻的元素中间。这时，算法将跳转到下一个层次，重复刚才的搜索，直到找到需要查找的元素为止。跳过的元素的方法可以是随机性选择或确定性选择，其中前者更为常见。([维基百科](https://zh.wikipedia.org/zh/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8)）

 ## Part2:SkipList 描述
 &ensp;&ensp;&ensp;&ensp;如下图，SkipList可视为水平排列 (Level)、垂直排列 (Tower) 的位置二维集合。每个 level 是一个链表 Level i，每个 Tower 包含存储连续链表中相同存储Key。具有 H 节点的 Tower 称为高度为 H，且每一个 Tower 的高度 H 是由抛硬币似的随机决定。Head Tower 和 Tail Tower 分别存储虚拟的Key。<br>
 &ensp;&ensp;&ensp;&ensp;除了首尾 Tower 的节点具有字段为：key、存储的值 value、向前指针 before、向下指针 down 以及一个指向根节点的指针 root；Head Tower 的节点不需要存储节点数据以及 root 指针等，但需要一个指向上一层的向上指针；Tail Tower只需要包含 key 即可，一般存储为 null 或 +∞。

 ![alt SkipList的设计图](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/skipList_design.png)

 ## Part3:SklipList的基本操作
 1. **查找节点**<br>
 如下图,加入要在一个skipList中寻找元素70，要经过以下步骤：
    - 从 Head Tower 的最高层级 Level4 从高到低开始，首先索引到 30 这个节点，且 30<70,继续索引 Level4 却没有后续节点；
    - 下降至 Level3 在节点 30 后索引到节点50，且 50<70，继续索引 Level3 却没有后续节点；
    - 下降至 Level2 在节点 50 后索引到节点70，且 50=70；
    - 在 Level1 中找到节点等于 70，该层节点即为节点 70 的根节点，同时表明查找成功；
    - 若在 Level 中仍没有查找到指定节点，表明查找失败。<br> 
    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/SkipList_search.png)

 2. **插入节点**<br>
 如下动图，动态详细的展示了在一个skipList中插入一个节点的过程：
    - 在插入节点的操作中，关键是在 Level1 中查找到一个合适的位置，即在所有小于待插入值的节点中找到最大节点。动图中所要插入的节点是 80，由上述**查找节点**的流程中，我们可以在 Level1 中查找到 70<80；
    - 且在 Level1 中 80<90，因而满足了插入条件；
    - 创建一个新节点并赋值为 80，将该结点作为根节点插入到 Level 的 70 与 90 之间，并调整指针方向；
    - 如图，我们取出随机函数（概率为1/2）来决定 Level2 中是否添加该节点，根据图示流程，我们在 Level2 中添加该节点索引。
    - 再次通过随机函数来决定 Level3 自己配每个是否添加该节点索引，添加失败。由此根节点为 80 的高度 H=2。<br>
    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/Skip_list_add_element-en.gif)

 3. **删除节点**<br>
 删除节点的关键同样是查找到该节点的位置
    - 在**查找节点**所示流程中，我们查找到指定节点位置；
    - 之后是删除节点，无论删除从上至下还是从下至上，都要在删除该层节点索引后维护好节点前指针和后指针的方向；
    - 最后是删除节点，释放空间。

 ## Part4：SkipList的分层如何实现
 1. 每一个 Tower 高度如何实现
    - William Pugh 是SkipList的发明者，他在定义 SkipList 时称其为“概率型”数据结构。这便指的是 Tower 的高度是随机的。
    - 在**插入节点**中提到确定了根节点的位置后仍要使用随机函数来确定是否要在上一层级添加该节点索引。
    - i 层节点索引出现在 i+1 层的概率 P 通常设计为 1/2 or 1/4。由此产生越高的节点层数，概率越低。
 2. SkipList 的高度控制
    - 限制最大高度：插入算法中限制最大高度，H=max{ 10,3*⌈logn⌉ }，当超过最大高度时候，即使随机函数确定增加 Tower 高度也不继续增加。
    - 不限制最大高度：以随机函数确定是否在 Tower 上继续添加索引。这种方法存在不安全可能性，即无限增高高度会占用太多内存，不过从上述可知概率很小。
 3. SkipList 的高度推导
    - P(Tower 的高度为 i) = P(连续 i 次随机数取值为1) = 1/2^i, i>=1 
    - P(Leveli 至少有1个元素)  <=n/(2^i),n 为跳表元素个数。
    - P(跳表高度大于 i) = P(Leveli 至少有 1 个元素) 。
    - 假设跳表高度为 3logn,则 P(h>3logn) <= n/(2^3logn) = 1/(n^2),假设跳表元素有 1000 个，则 P(h>3logn) 是百万分之一，反过来，有极大概率保证跳表的高度小于等于3 logn，故 h=O(logn)。

 ## Part5:时间复杂度 O(logn)
 在 SkipList 中最重要的操作是查找节点，而删除与添加操作都是在查找的基础上进行实现，且多出了对节点的指针改变算法，根据链表操作可知改变指针是在时间复杂度 O(1) 完成，所以，删除、添加与查找的时间复杂度相同。查找时间推导：
 - 查找包括两个循环，外层循环是从上层Level至底层Level，内层循环是在同一个Level，从左到右。
 - 因跳表高度以极大概率为O(logn)，所以外层循环的次数以极大概率为O(logn)。
 - 在上层查找比对过的key，不会再下层再次查找比对。且若概率为 1/2，则上一层大概率是本层一半的索引节点。假使每两个节点抽出一个节点为上一层节点，可得出结论每一层最多遍历 3 个索引节点，时间复杂度可为 O(1)。
 - 最终查找的时间=O(1)*O(logn)，也即O(logn)。

 ## Part6:SkipList 与 平衡树相比
 平衡树定义是改进的二叉查找树，一般的二叉查找树的查询复杂度取决于目标结点到树根的距离，当结点深度普遍较大时，查询复杂度会上升。为实现更高校的查询，在树创建过程中保持平衡，即所有叶子深度基本相同，这种树就是平衡树。如果让树维持平衡，就可以在 O(logn) 内完成正删改查操作。SkipList 与平衡树都是有序排列节点，但两者之间仍有许多不同：

 - 在做范围查找时候，平衡树比 SkipList 操作复杂；
    - **范围查找**是指查找两个值之间的所有节点。
    - 平衡树在查找到最小值位置后还要进行中序遍历才能找到其他节点
    - SkipList 只需要找到最小值后进行链表遍历即可实现
 - 插入、删除操作的区别；·
    - 平衡树在插入和删除节点后需要维持平衡而要进一步对树的其他节点进行位置调整，逻辑复杂；
    - 而 SkipList 只要修改相邻元素的指针即可实现
 - 从空间内存角度上；
    - 平衡树的每个节点要有两个指针，指向左右子树。
    - 而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。
 - 实现角度上更容易，平衡树的操作复杂，所以实现编程更复杂。

 ## Part7：为什么 SkipList 不再磁盘中使用
 - SkipList 是一个典型的“``空间换时间``”的应用，它是在链表基础上增加链表以及指针来实现快速查找，因此相比于树结构来说增加了不少空间压力。如果磁盘大量使用 SkipList 策略将导致空间占用，因此不可取。
 - SkipList 也被称为“概率树”，即数据结构创建的过程是存在概率因素，也就不能保证预期结果，所以不可取。

 # Data Structure 2：B-Tree 的学习
 ## Part1：B树介绍

 - B树定义：在计算机科学中，B树（英语：B-tree）是一种自平衡的树，能够``保持数据有序``。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数时间内完成。B树，概括来说是一个一般化的``二叉查找树（binary search tree）``一个节点可以拥有2个以上的子节点。与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。B树减少定位记录时所经历的中间过程，从而加快存取速度。B树这种数据结构可以用来描述外部存储。这种数据结构常被应用在数据库和文件系统的实现上。([维基百科](https://zh.wikipedia.org/wiki/B%E6%A0%91))
 - 一个 m 阶的B树是一个有以下属性的树：
    1. 每一个节点最多有 m 个子节点
    2. 每一个非叶子节点（除根节点）最少有 ⌈m/2⌉ 个子节点
    3. 如果根节点不是叶子节点，那么它至少有两个子节点
    4. 所有的叶子节点都在同一层
    5. 每个非叶子节点由 n 个 key 和 n+1 个指针组成，其中 ⌈m/2⌉-1 <= n <= m-1

 ## Part2:B-Tree 的基本操作

 - **搜索**：B树的搜索和二叉搜索树类似。从根节点开始，从上到下递归的遍历树。在每一层上，搜索的范围被减小到包含了搜索值的子树中。``子树值的范围被它的父节点的键确定``。
 - **插入**：``所有的插入都从根节点开始``。要插入一个新的元素，首先搜索这棵树找到新元素应该被添加到的对应节点。将新元素插入到这一节点中的步骤如下：
    1. 如果节点拥有的元素数量小于最大值，那么有空间容纳新的元素。将新元素插入到这一节点，且保持节点中元素有序。
    2. 否则的话这一节点已经满了，将它``平均地分裂成两个节点``：
        1. 从该节点的原有元素和新的元素中选择出中位数
        2. 小于这一中位数的元素放入左边节点，大于这一中位数的元素放入右边节点，中位数作为分隔值。
        3. 分隔值被插入到父节点中，这可能会造成父节点分裂，分裂父节点时可能又会使它的父节点分裂，以此类推。如果没有父节点（这一节点是根节点），就创建一个新的根节点（增加了树的高度）。
    > 以 5 叉 B 树为例，根据属性 5 则每一个节点有 4 个键时候产生分裂；以C N G A H E K Q M F W L T Z D P R X Y S为顺序插入构造。([演示工具](https://www.cs.usfca.edu/~galles/visualization/BTree.html))
    1. 插入前 4 个字母 C N G A

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/BTree01.png)
    2. 插入 H，应为节点的 G 和 N 之间，但节点有 5 个键，需要产生分裂。以 A C G H N 可得中位数为 G，向上分裂为父节点

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/Btree02.png)
    3. 插入 E，先与 G 进行比较后插入到 G 的左孩子，再与 A C 比较，插入到 C 的右侧；同理，插入 K Q

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/BTree03.png)
    4. 插入 M，先与 G 进行比较后插入 G 的右孩子，此时为 H K M N Q，此时有 5 个键，以 M 为中位数进行分裂，且将 M 插入到父节点中。父节点因此多出一个键和一个指针

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/Btree04.png)
    5. 插入 F W L T，无需分裂

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/Btree05.jpg)
    6. 插入 Z，先与 G M 比较，再与 N Q T W 比较，以 T 为中位数分裂到父节点

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/BTree06.png)
    7. 插入 D，与 G 比较后与 A C E比较，插入后 A C D E F，以 D 为中位数向上分裂

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/BTree07.jpg)
    8. 插入 P R X Y，不需要分裂

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/BTree08.png)
    9. 最后插入 S，与 D G M T 比较后插入 M 与 T 之间的指针所指的孩子。此时该孩子键为 N P Q R S，以 Q 为中位数向上分裂为父节点的键。此时父节点为 D G M S T，需要再以 M 为中位数，再生成一个父节点。

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/BTree09.png)
 - **删除**:首先在 B 树中查找要删除的元素，如果存在则删除该元素，然后调整树使它满足约束条件。
    - 删除一个元素可能出现两种特设情况
        1. 这个元素用于分隔一个内部节点的子节点
        2. 删除元素会导致它所在的节点的元素或子节点数量小于最低值
    - 下面是处理过程
        - **删除叶子节点的元素**
            1. 搜索要删除的元素
            2. 如果它在叶子节点，将它从中删除
            3. 如果发生了下溢出，按照后面 “删除后重新平衡”部分的描述重新调整树
        - **删除内部节点中的元素**
            > 内部节点中的每一个元素都作为分隔两颗子树的分隔值，因此我们需要重新划分。值得注意的是左子树中最大的元素仍然小于分隔值。同样的，右子树中最小的元素仍然大于分隔值。这两个元素都在叶子节点中，并且任何一个都可以作为两颗子树的新分隔值。算法的描述如下：
            1. 选择一个新的分隔符（左子树中最大的元素或右子树中最小的元素），将它从叶子节点中移除，替换掉被删除的元素作为新的分隔值。
            2. 前一步删除了一个叶子节点中的元素。如果这个叶子节点拥有的元素数量小于最低要求，那么从这一叶子节点开始重新进行平衡。
        - **删除后的重新平衡**
            > ``重新平衡从叶子节点开始向根节点进行，直到树重新平衡``。如果删除节点中的一个元素使该节点的元素数量低于最小值，那么一些元素必须被重新分配。通常，移动一个元素数量大于最小值的兄弟节点中的元素。如果兄弟节点都没有多余的元素，那么缺少元素的节点就必须要和他的兄弟节点合并。合并可能导致父节点失去了分隔值，所以父节点可能缺少元素并需要重新平衡。合并和重新平衡可能一直进行到根节点，根节点变成惟一缺少元素的节点。重新平衡树的算法如下：
            - 如果缺少元素节点的右兄弟存在且拥有多余的元素，那么向左旋转
                1. 将父节点的分隔值复制到缺少元素节点的最后（分隔值被移下来；缺少元素的节点现在有最小数量的元素）
                2. 将父节点的分隔值替换为右兄弟的第一个元素（右兄弟失去了一个节点但仍然拥有最小数量的元素）
                3. 树又重新平衡
            - 否则，如果缺少元素节点的左兄弟存在且拥有多余的元素，那么向右旋转
                1. 将父节点的分隔值复制到缺少元素节点的第一个节点（分隔值被移下来；缺少元素的节点现在有最小数量的元素）
                2. 将父节点的分隔值替换为左兄弟的最后一个元素（左兄弟失去了一个节点但仍然拥有最小数量的元素）
                3. 树又重新平衡
            - 否则，如果它的两个直接兄弟节点都只有最小数量的元素，那么将它与一个直接兄弟节点以及父节点中它们的分隔值合并
                1. 分隔值复制到左边的节点（左边的节点可以是缺少元素的节点或者拥有最小数量元素的兄弟节点）
                2. 将右边节点中所有的元素移动到左边节点（左边节点现在拥有最大数量的元素，右边节点为空）
                3. 将父节点中的分隔值和空的右子树移除（父节点失去了一个元素）
                    - 如果父节点是根节点并且没有元素了，那么释放它并且让合并之后的节点成为新的根节点（树的深度减小）
                    - 否则，如果父节点的元素数量小于最小值，重新平衡父节点

    > 上述实验构建的 B 树，现在依次 H T R E 删除；该树是 5 叉 B 树，那么每个节点最小键数为 ⌈m/2⌉-1 = 2
    1. 删除 H，首先要查找 H，它在一个叶子节点中且叶子节点数为 3>2，则直接删除即可。
    
        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/BTree_DEL01.png)
    2. 删除 T，T所在节点非叶子节点，属于内部节点。那么删除 T，再选择一个子树中 key 最多的节点，选择一个作为新的分隔元素，本示例中为右子树的 W。

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/BTree_DEL02.png)
    3. 删除 R,R 所在节点 key 为 2 个，删除 R 后该节点元素小于最小元素数目。则寻找兄弟节点中拥有富余元素最多的兄弟。将父节点的分隔点放到删除元素的节点中，将选中的兄弟节点中选中一个元素上升为父节点元素成为新的分隔点。本示例为“左旋转”

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/BTree_DEL03.jpg)
    4.最后一步删除 E。
        - E 所在节点刚好达标，删除后要向父节点借用一个元素，但周围的兄弟都没有富余的元素可以“左旋转”或者“右旋转”
            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/BTree_DEL04.jpg)
        - 则需要进行合并操作。先将父节点的分隔点下沉到一个兄弟节点中，并与删除元素的节点合并
        
            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/BTree_DEL05.jpg)
        - 此时父节点只剩下一个元素，不满足最小元素数，但兄弟节点不满足“右旋转”，这时要将该节点的父节点下沉一个元素，并与**删除元素的节点**以及其**有两个元素的兄弟节点**合并

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/BTreeDEL06.jpg)
        - 结果是树的高度减少一层

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/BTreeDEL07.jpg)

 ## Part3:B-Tree 的时间复杂度
 对于 B 树的操作，无论是插入、删除，其实主要工作是要查找到元素的位置，在树的数据结构中，搜索元素位置与树的高度成正比关系。B 树高度 $H <= log_T\frac{n+1}{2} <= log_2n$，其中 T 为阶数，n 为元素总数。我们可以大致认为查找深度为logn，且每一层节点查找元素个数为有限个元素认为查找为 O(1),所以 B 树的查找、删除和插入时间复杂度为 O(logn)

 ## Part4:B-Tree 的优势
 1. 提高 IO 性能，缩短与磁盘交互次数。同样的数据量使用二叉查找树，将极大加深了树的深度，每一个树节点对应磁盘一个磁盘页，从而使得查询多次使用磁盘 IO。
 2. 降低搜索复杂度，相比于链表等数据结构，使用树结构可以根据比较不断缩小搜索范围，从而提高查询效率。
 3. 可以保持键值有序，遍历操作可以顺序输出
 4. 使用算法可以在任何操作后保持树的平衡性
 5. 通过保证内部节点有最小元素数，超过最小元素数后进行合并，进而减少空间浪费

 ## Part5:B-Tree 的应用
 B 树 适合应用数据库的索引或者是文件系统，最典型的应用是 mongodb 的数据索引。mongdb 是聚合型数据库，比较适合 B 树的键域和数据域的集群，使用 B 树在只要查找到指定索引就可以进行访问，而 mongdb 也倾向于对单个元素的查找，所以 mongdb 适合使用这种数据结构。


 # Data Structure 3：B+Tree 的学习
 ## Part1：B+Tree 的介绍
 B+ 树与 B 树基本相似，可以说是 B 树的改进版。同样适合数据库和操作系统中的文件系统中引用。其插入、删除等操作也是在对数时间内完成。其特殊之处 ``B+ 树的数据都存储在叶子结点中，分支结点均为索引``，方便扫库，只需要扫一遍叶子结点即可。
 - 其基本结构是：在 B+ 树中的节点通常被表示为一组``有序``的元素和子指针。如果此 B+ 树的阶数是 m，则除了根之外的每个节点都包含最少 $\lfloor m/2\rfloor$ 个元素最多 ${\displaystyle m-1}$ 个元素，对于任意的结点有最多 m 个子指针。对于所有内部节点，子指针的数目总是比元素的数目多一个。``所有叶子都在相同的高度上``，叶结点本身按关键字大小从小到大链接。
 
 ## Part2：B+Tree 的操作
 - **查找**：查找以典型的方式进行，类似于二叉查找树。起始于根节点，自顶向下遍历树，选择其分离值在要查找值的任意一边的子指针。``在节点内部典型的使用是二分查找来确定这个位置``。
 - **插入**：节点要处于违规状态，即它必须包含在可接受范围之外数目的元素。
    1. 首先，查找要插入其中的节点的位置。接着把值插入这个节点中。
    2. 如果没有节点处于违规状态则处理结束。
    3. 如果某个节点有过多元素，则把它分裂为两个节点，每个都有最小数目的元素。在树上递归向上继续这个处理直到到达根节点，如果根节点被分裂，则创建一个新根节点。为了使它工作，元素的最小和最大数目典型的必须选择为使最小数不小于最大数的一半。
        - **针对叶子类型结点**：根据 key 值找到叶子结点，向这个叶子结点插入记录。插入后，若当前结点 key 的个数小于等于 m-1 ，则插入结束。否则将这个叶子结点分裂成左右两个叶子结点，左叶子结点包含前 m/2 个记录，右结点包含剩下的记录，将第 m/2+1 个记录的 key 进位到父结点中（父结点一定是索引类型结点），进位到父结点的key左孩子指针向左结点,右孩子指针向右结点。将当前结点的指针指向父结点
        - **针对索引类型结点**：若当前结点 key 的个数小于等于 m-1，则插入结束。否则，将这个索引类型结点分裂成两个索引结点，左索引结点包含前 (m-1)/2 个 key，右结点包含 m-(m-1)/2 个 key，将第 m/2 个 key进位到父结点中，进位到父结点的 key 左孩子指向左结点, 进位到父结点的 key 右孩子指向右结点。将当前结点的指针指向父结点。

    > 以 5 叉 B+ 树为例，根据属性 5 则每一个节点有 4 个键时候产生分裂；以C N G A H E K Q M F W L T Z D 为顺序插入构造。([演示工具](https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html))
    1. 插入前4个元素 C N G A，此时只有一个节点与 B 树一致会将元素排列好

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree01.jpg)
    2. 插入 H
        - 首先插入节点中并排序

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+tree02.jpg)
        - 然后由于元素数大于最大元素数，所以开始分裂。但与 B 树不同在于所有元素仍然在叶子节点中，并使用链表指针将叶子节点相连。其向上分裂的父节点只存索引。

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree03.jpg)
    3. 插入 E K，分别根据 G 索引在左右子树中插入，由于左右子树插入元素后仍不超过最大元素数，所以合规。
        
        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree04.jpg)
    4. 插入 Q
        - 首先比对 G 索引，然后 Q>G，在 G 的右子树合适位置插入

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree05.jpg)
        - 此时右子树节点元素个数超过节点最大元素数，进行向上分裂。取出中位数 K 向上为父节点的元素，再分裂其余元素为叶子节点并用指针相连。

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree06.jpg)
    5. 插入 M F，找到合适的叶子节点直接插入

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree07.jpg)
    6. 插入 W，产生向上分裂，与第 4 步过程相同
        
        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree08.jpg)
    7. 插入 W L T 后不会分裂；再插入 Z，则同第 4、6 步相同过程
        
        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree09.jpg)
    8. 插入D
        - 首先根据搜索结果在合适节点插入

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree10.jpg)
        - 由于插入节点元素数过多进而向上分裂

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree11.jpg)
        - 但由于向上分裂导致根节点元素数过多，从而分裂根节点产生新的根节点。

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree12.jpg)
 - **删除**
    1. 首先，查找要删除的值。接着从包含它的节点中删除这个值。
    2. 如果没有节点处于违规状态则处理结束。
    3. 如果节点处于违规状态则有两种可能情况：
        1. 它的兄弟节点，就是同一个父节点的子节点，可以把一个或多个它的子节点转移到当前节点，而把它返回为合法状态。如果是这样，在更改父节点和两个兄弟节点的分离值之后处理结束。
        2. 它的兄弟节点由于处在低边界上而没有额外的子节点。在这种情况下把两个兄弟节点合并到一个单一的节点中，而且我们递归到父节点上，因为它被删除了一个子节点。持续这个处理直到当前节点是合法状态或者到达根节点，在其上根节点的子节点被合并而且合并后的节点成为新的根节点。

    > 如上述构建的 B+Tree，我们以此来进行删除操作展示具体执行过程。
    1. 删除 M，搜索到该元素后直接删除，且删除后所属节点依旧合法，结束

        ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree_DEL01.jpg)
    2. 删除 A
        - 首先分析删除 A 后状态，所属节点已经元素不足。

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree_DEL02.jpg)
        - 此时它的兄弟节点元素富余，则进行“左旋”

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree_DEL03.jpg)
    3. 删除L
        - 删除 L 后，与第 2 步同样是遇到元素不足

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree_DEL04.jpg)
        - 但不同的是它的兄弟节点也没有富余元素，所以不能“左旋”。那么选择操作是取父节点的分隔元素下沉，再与本节点和兄弟节点进行``合并``。

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree_DEL05.png)
        - 但此时被移除元素的父节点不再满足最低元素数，同上步基本相同，向上借用一个元素，即根节点的 K 下沉。从而导致树高度减一

            ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree_DEL06.jpg)

 ## Patr3：B+ 树的其他
 ### B+Tree 的时间复杂度为O(logn)

 ### B+ 树的特性
 - 每个节点中子节点的个数不能超过 m，也不能小于 m/2
 - 根节点的子节点个数可以不超过 m/2，这是一个例外
 - m 叉树只存储索引，并不真正存储数据，这个有点儿类似跳表
 - 通过链表将叶子节点串联在一起，这样可以方便按区间查找
 - 一般情况，根节点会被存储在内存中，其他节点存储在磁盘中

 ### B+ 树相当于 B 树的优点：
 - B+树的层级更少：B+树每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快；
 - B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;
 - B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。
 - B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。<br>
    - ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+TreePrint.gif)

 ### B+ 树为什么适合磁盘索引
 - B+树的磁盘读写代价更低。B+树的内部结点并没有指向关键字具体信息的指针，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素。
 - B+树的查询效率更加稳定 由于内部结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。
- B+树更有利于对数据库的扫描 B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题，而B+树只需要遍历叶子节点就可以解决对全部关键字信息的扫描，所以对于数据库中频繁使用的range query，B+树有着更高的性能。

 ### B+ 树在 MySQL 中应用
 - 在数据库中一般使用索引的情况下是有较大的数据量，那么创建出的索引文件也会很大，所以索引一般不能直接存储在内存中，而是存储在硬盘内。所以要提高 IO 速度必须减少磁盘访问次数，由上部分讨论可知 B+ 树有一定的优势。
 - 且 B+ 树的非叶子节点只存储关键字信息，没有存储相关数据或数据指针，所以在树高度相同情况下 B+ 树可以存储更多关键字信息
 - 更重要的是 B+ 树的叶子节点存储了所有关键字信息以及对应的数据指针。这些叶子节点构造有序链表，很容易实现范围查找。``且数据库使用了双向链表，更快捷的进行升序和降序语法的实现``。
 
    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/B+Tree%E5%BA%94%E7%94%A8.jpg)


# Data Structure 4：LSM-Tree（Log Structured Merge Tree）的学习
## Part1：LSM-Tree 的介绍
- 背景引入：首先我们看一下下图所示内容，清晰的表明了一个事实，``顺序读写磁盘（不管是SATA还是SSD）快于随机读写主存``，而且快至少三个数量级。这说明我们要``避免随机读写，最好设计成顺序读写``。 

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/DiskRandomSequential.png)
- 如果我们对写操作的吞吐量敏感，我们最好怎么做？一个好的办法是简单的将数据添加到文件。这个策略经常被使用在日志或者堆文件，因为他们是完全顺序的，所以可以提供非常好的写操作性能，大约等于磁盘的理论速度，也就是200~300 MB/s。 
    - 同时他们也有一些缺点，从日志文件中读一些数据将会比写操作需要更多的时间，需要倒序扫描，直接找到所需的内容。
    - 所以，我们需要更多的日志来为更复杂的读场景（比如按 key 或者 range）提供高效的性能，这儿有4个方法可以完成这个，它们分别是： 
        1. 二分查找: 将文件数据有序保存，使用二分查找来完成特定key的查找
        2. 哈希：用哈希将数据分割为不同的 bucket 
        3. B+树：使用B+树 或者 ISAM 等方法，可以减少外部文件的读取 
        4. 外部文件： 将数据保存为日志，并创建一个 hash 或者查找树映射相应的文件
    - 所有的方法都可以有效的提高了读操作的性能 (最少提供了 O(log(n)))，但是，却丢失了日志文件超好的写性能。上面这些方法，都强加了总体的结构信息在数据上，数据被按照特定的方式放置，所以可以很快的找到特定的数据，但是却``对写操作不友善，让写操作性能下降``。
- 所以这就是 LSM 被发明的原理， LSM 使用一种不同于上述四种的方法，保持了日志文件写性能，以及微小的读操作性能损失。``本质上就是让所有的操作顺序化，而不是像散弹枪一样随机读写``。
- **LSM-Tree定义**：将整个磁盘就看做是一个日志，在日志中存放永久性数据及其索引，每次都添加到日志的末尾；通过将很多小文件的存取转换为连续的大批量传输，使得对于文件系统的大多数存取都是顺序性的，从而提高磁盘带宽利用率，故障恢复速度快。
- **LSM-Tree核心思想**：就是将写入推迟 (Defer) 并转换为批量 (Batch) 写，``首先将大量写入缓存在内存，当积攒到一定程度后，将他们批量写入文件中``，这要一次 I/O 可以进行多条数据的写入，充分利用每一次 I/O。
- ``适合存储 key 值有序且写入大于读取的数据，或者读取操作通常是 key 值连续的数据``。

## Part2:LSM_Tree 的存储结构
- 存储模型
    - **WAL**：（write ahead log）也称预写log，包括mysql的Binlog等,在设计数据库的时候经常被使用，``当插入一条数据时，数据先顺序写入 WAL 文件中，之后插入到内存中的 MemTable 中``。这样就保证了数据的持久化，不会丢失数据，并且都是顺序写，速度很快。当程序挂掉重启时，可以从 WAL 文件中重新恢复内存中的 MemTable。
    - **MemTable**：MemTable 对应的就是 WAL 文件，是该文件内容在内存中的存储结构，通常用 SkipList 来实现。``MemTable 提供了 k-v 数据的写入、删除以及读取的操作接口``。其内部将 k-v 对按照 key 值有序存储，这样方便之后快速序列化到 SSTable 文件中，仍然保持数据的有序性。
    - **Immutable Memtable**：顾名思义，Immutable Memtable 就是在内存中只读的 MemTable，由于内存是有限的，通常我们会设置一个阀值，``当 MemTable 占用的内存达到阀值后就自动转换为 Immutable Memtable``，Immutable Memtable 和 MemTable 的区别就是它是只读的，``系统此时会生成新的 MemTable 供写操作继续写入``。之所以要使用 Immutable Memtable，就是为了避免将 MemTable 中的内容序列化到磁盘中时会阻塞写操作。
    - **SSTable**：SSTable 就是 MemTable 中的数据在磁盘上的有序存储，``其内部数据是根据 key 从小到大排列的``。通常为了加快查找的速度，需要在 SSTable 中加入数据索引，可以快读定位到指定的 k-v 数据。
    
> SSTable 通常采用的分级的结构，例如 LevelDB 中就是如此。MemTable 中的数据达到指定阀值后会在 Level 0 层创建一个新的 SSTable。当某个 Level 下的文件数超过一定值后，就会将这个 Level 下的一个 SSTable 文件和更高一级的 SSTable 文件合并，由于 SSTable 中的 k-v 数据都是有序的，相当于是一个多路归并排序，所以合并操作相当快速，最终生成一个新的 SSTable 文件，将旧的文件删除，这样就完成了一次合并过程。<br>
    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/LSM-Tree01.jpg)
    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/LSMTree02.jpg)

## Part3:LSM-Tree 的基本操作
### LSM-Tree 的创建
- LSM树由两个或更多树组件构成，以二组件示例

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/LSMTree03.jpg)
    - 一个较小的位于内存的组件，就是上图中的 C0 tree
    - 一个较大的位于磁盘的组件，就是上图中的C1 tree
- **插入一条数据**
    1. 首先向顺序日志文件中写一条用于恢复这次插入行为的日志记录
    2. 该行数据的索引被插入到常驻内存的 C0 树中
    3. 会适时地将这些C0树上的数据迁移到磁盘上的C1树中
    4. 每个索引的搜索过程都是先C0后C1
- 组件合并过程<br>
    LSM树采用的方法是当C0树上的插入的数据几乎达到指定的阈值时，有一个持续循环的合并进程服务会删除C0树上的一些连续segment段，将他们合并到磁盘中的C1树。**注意，新合并的块会被写入新的磁盘位置，这使得旧的块不会被覆盖。这样的好处是可在系统崩溃时快速恢复。**

    ![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/BTree04.jpg)

    上面的图中下方圆圈内就是新的多页block，包含了merge结果。随后的合并步骤持续将C0和C1组件的增加的索引值段汇集在一起，直到达到最大值，此时滚动合并又从最小值再次开始。
    1. 当增长中的C0树第一次达到阈值的时候
    2. 最靠左的一系列条目会以高效批量形式从C0树中删除
    3. 然后被重组到C1树(按key递增顺序)，将被完全填满
    4. 连续的C1树的叶节点会按从左到右的顺序，首先被放置到常驻内存的多页块内的若干初始页上
    5. 持续上一步直到该多页块被填满
    6. 然后该多页块被刷到磁盘，成为C1树叶节点层的第一部分，常驻磁盘
    7. 随着这些连续的叶节点添加的过程，一个C1树的目录节点结构会在内存缓存中被创建（这些上层目录节点被存在单独的多页块缓存或单独的页缓存中，为了更高效利用内存和磁盘。其中还包含分隔点索引，可以将访问精确匹配导向某个下一层级的单页节点而不是多页块，类似B树。这样一来，我们就可在滚动合并或长范围搜索时使用多页块，而在索引精确匹配访问时使用单页节点）
    8. 在发生如下情况时，C1的目录节点会被强制刷盘
        - 包含目录节点的多页块缓存满了 -> 只有该多页块会被刷盘
        - 根节点分裂，增加了C1树的深度(大于2) -> 所有多页块刷盘
        - checkpoint被执行-> 所有多页块刷盘

### LSM-Tree 的搜索
当一个需要立刻返回的精确匹配查询或是范围查询在 LSM 树的索引上执行时，会先在 C0 树执行搜索值，然后搜 C1 树。这暗含着少许额外的CPU开销(相对于 B 树来说)，因为分别去两棵树目录进行搜索。

![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/LSMTree05.jpg)

如上图，考虑多个组件的LSM树，拥有 C0, C1, C2 .... Ck，这样一个递增的索引树结构。其中C0是驻留在内存的，而且他组件都在磁盘。这种情况下，``每当Ci-1 条目达到阈值时，每个 (Ci-1,Ci) 之间的异步滚动合并过程会从较小的组件中移动条目到较大的组件``。

### LSM-Tree 的删除
``删除也可以和插入一样享用延迟和批处理的好处``。 具体来说，当一个索引行被删除时，如果一个 key-value 键值对没有在 C0 树中找到，那么可以把一个删除节点条目放到该位置，同样会被key索引，但该索引指向一个应该被删除的条目。而真正的删除可在稍后的滚动合并过程中扫描到真正的该索引条目时完成：``其实就是将删除节点条目合并到更大的组件时，遇到对应的真实条目是就之间被真正删除了``。

同时，``查找请求必须被那些删除节点条目过滤掉，避免结果中返回要被删除的记录``。这个过滤很容易实现，很容易想到那些删除节点条目肯定是在相较于真实条目较早的组件上，这样还能使得搜索尽量早的发现条目被删除而不必搜索到最后的组件才返回。

## Part4：LSM-Tree的其他
## LSM-Tree VS B+Tree
- LSM-Tree 通常对于写入更友好，而 BTree 则对于读应用更友好。
- BTree 在写入数据的时候，需要写入WAL和页，并且每次都要写整个页，还可能发生页分裂。而 LSTM-Tree 不是面向页的操作，其能更好的利用顺序写的优势，写入通常更快。
- 面对精确的查询需求，BTree 往往有更大的优势。不仅如此，在需要实现事务的场景下，数据库采用 BTree 也会更方便，因为可以直接在树上实现锁。而 LSM-Tree 的结构，要想实现锁，可能还得新增其他数据结构。

## LSM-Tree 的应用
![](https://cdn.jsdelivr.net/gh/Beeter-yong/pictures/imgOne/LSMTreeApplication.jpg)